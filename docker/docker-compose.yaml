version: '3'

services:
    zookeeper:
        image: confluentinc/cp-zookeeper:latest
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181

    kafka:
        image: confluentinc/cp-kafka:latest
        depends_on:
            - zookeeper
        ports:
            - '9092:9092'
            - '9094:9094'
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
            KAFKA_LISTENERS: INTERNAL://:9092,OUTSIDE://:9094
            KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://localhost:9094
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT

    kafka-topics-generator:
        image: confluentinc/cp-kafka:latest
        depends_on:
            - kafka
        command: >
            bash -c
              "sleep 5s && kafka-topics --create --topic=tp.create-survey --if-not-exists --bootstrap-server=kafka:9092"
    kafdrop:
        image: obsidiandynamics/kafdrop:latest
        depends_on:
            - kafka
        ports:
            - "9000:9000"
        environment:
            KAFKA_BROKERCONNECT: kafka:9092
    db:
        container_name: postgres-db
        image: postgres:latest
        environment:
            - POSTGRES_USER=user
            - POSTGRES_PASSWORD=pass
            - POSTGRES_DB=survey-api
        ports:
            - "5432:5432"
        volumes:
            - survey-api:/var/lib/postgresql/data

volumes:
  survey-api:
  localstack-data:
    driver: local

## TODO: Criar Dockerfile para api e worker e subir eles no docker-compose para ter as duas instancias de cada no ar para fazer o load balance
